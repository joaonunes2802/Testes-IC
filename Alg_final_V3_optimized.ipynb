{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgoSRhoMADjE"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# URLLC DRX possible configurations\n",
    "\n",
    "deltaU = [2, 3, 4, 5, 6, 7, 8, 10, 14, 16, 20, 30, 32, 35, 40, 64, 80, 128, 160,\n",
    "          256, 320, 512, 640]  # Set of Cycle Lenghts\n",
    "fiU = [1, 2, 3, 4, 5, 6, 8, 10, 20, 30, 40, 50, 60, 80, 100, 200, 300, 400, 500,\n",
    "       600, 800, 1000, 1200, 1600]  # Set of ON periods\n",
    "\n",
    "\n",
    "\n",
    "omegaU = [25000, 30000, 40000, 50000]  #KHz\n",
    "packetSizeU = [900, 1000, 1100, 1200]\n",
    "\n",
    "# eMBB DRX possible configurations\n",
    "deltaE = [10, 20, 32, 40, 60, 64, 70, 80, 128, 160, 256, 320, 512, 640, 1024, 1280,\n",
    "          2048, 2560, 5120, 10240, 20480]\n",
    "fiE = [1, 2, 3, 4, 5, 6, 8, 10, 20, 30, 40, 50, 60, 80, 100, 200, 300, 400, 500,\n",
    "       600, 800]\n",
    "gamaE = [0, 10, 20, 32, 40, 60, 64, 70, 80, 128, 160, 256, 320, 512, 640, 1024, 1280,\n",
    "         2048, 2560, 5120, 10240]\n",
    "\n",
    "\n",
    "omegaE = [5000, 10000, 15000, 20000, 25000, 30000]  #KHz\n",
    "packetSizeE = [6000, 7000, 8000, 9000]\n",
    "\n",
    "# Power Comsuption\n",
    "\n",
    "Pmax = 10000\n",
    "beta = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3FDQyq1YISb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Mapa de PRBs e usuários por BWP\n",
    "def calculate_prbs_and_k(bwp):\n",
    "    \"\"\"Retorna a quantidade de PRBs e o número de usuários no DCI para um dado BWP.\"\"\"\n",
    "    prbs_k_map = {\n",
    "        5000: (25, 1),\n",
    "        10000: (52, 2),\n",
    "        15000: (79, 3),\n",
    "        20000: (106, 4),\n",
    "        25000: (133, 5),\n",
    "        30000: (160, 6),\n",
    "        40000: (216, 8),\n",
    "        50000: (270, 10)\n",
    "    }\n",
    "    return prbs_k_map.get(bwp, (0, 1))\n",
    "\n",
    "# Calcula o sinal de um usuário com base em PRBs e K\n",
    "def calculate_signal(prbs, ks):\n",
    "    \"\"\"\n",
    "    Calcula o sinal de um UE considerando uma distribuição de Rayleigh.\n",
    "    Aqui usamos o valor esperado para evitar cálculos aleatórios.\n",
    "    \"\"\"\n",
    "    rayleigh_mean = np.sqrt(np.pi / 2)  # Valor esperado para escala σ=1\n",
    "    num_samples = prbs // ks           # Número de amostras de ganho\n",
    "    total_signal = num_samples * rayleigh_mean\n",
    "    return total_signal\n",
    "\n",
    "# Calcula a relação SNIR para cada usuário\n",
    "def compute_snir(df_target, df_interferers):\n",
    "    \"\"\"\n",
    "    Calcula a relação sinal-ruído para os usuários no `df_target`, \n",
    "    considerando interferência dos usuários no `df_interferers`.\n",
    "    \"\"\"\n",
    "    snir_list = []\n",
    "\n",
    "    for row in df_target.itertuples():\n",
    "        bwp = row[5]\n",
    "        prbs, k = calculate_prbs_and_k(bwp)\n",
    "        signal = calculate_signal(prbs, k)\n",
    "\n",
    "        # Interferência de UEs na mesma BWP, mas em outra célula\n",
    "        interference = sum(\n",
    "            calculate_signal(prbs, k) for interferer in df_interferers.itertuples()\n",
    "            if interferer[5] == bwp\n",
    "        )\n",
    "\n",
    "        # Cálculo do SNIR: Sinal / (Interferência + Ruído térmico)\n",
    "        noise_floor = 114  # dBm\n",
    "        snir = signal / (interference + noise_floor)\n",
    "        snir_list.append(snir)\n",
    "\n",
    "    return np.array(snir_list)\n",
    "\n",
    "# Scheduler: Aplica o cálculo da relação SNIR\n",
    "def scheduler(df):\n",
    "    \"\"\"\n",
    "    Calcula a relação SNIR para os usuários em duas células\n",
    "    e adiciona a coluna 'SNIR' ao DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by='Cell_Site', ascending=True)\n",
    "\n",
    "    # Divide o DataFrame por célula\n",
    "    df1 = df.query(\"Cell_Site == 1\")\n",
    "    df2 = df.query(\"Cell_Site == 2\")\n",
    "\n",
    "    # Calcula SNIR para cada célula\n",
    "    snir_1 = compute_snir(df1, df2)\n",
    "    snir_2 = compute_snir(df2, df1)\n",
    "\n",
    "    # Adiciona coluna SNIR ao DataFrame original\n",
    "    df['SNIR'] = np.concatenate((snir_1, snir_2))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9RGjy18rNib"
   },
   "outputs": [],
   "source": [
    "# Faz o cáculo da Capacidade de Shannon para cada UE, usando sua SNIR e BWP consumida\n",
    "def shannonCapacity(df):\n",
    "  snirs = np.array(df['SNIR'])\n",
    "  bwps = np.array(df['BWP [MHz]'])\n",
    "  logaux = 1 + snirs\n",
    "  log2 = np.log2(logaux)\n",
    "  shannonCapacity = np.multiply(bwps, log2)\n",
    "  shannonCapacity = shannonCapacity.tolist()\n",
    "  df['Shannon_Capacity'] = shannonCapacity\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JP8Hyev5UgA8"
   },
   "outputs": [],
   "source": [
    "def inicializaUE(nURLLC, nEMBB):\n",
    "    # Inicialização de lista para acumular os dados antes de criar o DataFrame\n",
    "    data = []\n",
    "    beta = []\n",
    "    aux = 0\n",
    "    \n",
    "    total_users = nURLLC + nEMBB\n",
    "    half_nURLLC = nURLLC // 2\n",
    "    half_nEMBB = nEMBB // 2\n",
    "\n",
    "    for i in range(total_users):\n",
    "        if i < nURLLC:  # Usuários URLLC\n",
    "            cell = 1 if aux <= half_nURLLC else 2\n",
    "            line = [\"URLLC\", 1, 1, 1, 10000, 100, cell]\n",
    "            b = 0.4 + (0.6 * (30 / 80))  # Cálculo de beta\n",
    "            beta.append(b)\n",
    "        else:  # Usuários eMBB\n",
    "            if i == nURLLC:  # Reset do contador aux ao finalizar os URLLC\n",
    "                aux = 0\n",
    "            cell = 1 if aux <= half_nEMBB else 2\n",
    "            line = [\"eMBB\", 1, 1, 1, 50000, 1000, cell]\n",
    "            b = 0.4\n",
    "            beta.append(b)\n",
    "        \n",
    "        data.append(line)\n",
    "        aux += 1\n",
    "    \n",
    "    # Criação do DataFrame a partir da lista de dados\n",
    "    dfUE = pd.DataFrame(data, columns=['Usuário', 'Cycle Length [ms]', 'onTime [ms]', 'offset [ms]', \n",
    "                                       'BWP [MHz]', 'Packet Size [bytes]', 'Cell_Site'])\n",
    "\n",
    "    # Chamadas adicionais para processar o DataFrame\n",
    "    dfUE = scheduler(dfUE)\n",
    "    dfUE = shannonCapacity(dfUE)\n",
    "    \n",
    "    return dfUE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyBqr0cgkWxD"
   },
   "outputs": [],
   "source": [
    "def offsets_(UE):\n",
    "  #Retorna o começo de cada offset na lina do tempo\n",
    "  # Exemplo: 0s-------10s-------20s\n",
    "  # Cada tempo representa um offset\n",
    "\n",
    "  cycle = UE[2]\n",
    "  offsetsTimes = np.array([])\n",
    "  qtdCycle = 100/cycle\n",
    "  i = 0\n",
    "  while i <= qtdCycle:\n",
    "    offsetsTimes = np.append(offsetsTimes, cycle * i)\n",
    "    i += 1\n",
    "  return offsetsTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9_x3kLhmf9C"
   },
   "outputs": [],
   "source": [
    "def onTimes_(UE):\n",
    "  # Retorna o começo de cada on\n",
    "  # Ex: 5s----15s-----25s\n",
    "  # Cada tempo representa o começo de um período de ON\n",
    "\n",
    "  offL = UE[4]\n",
    "  cycle = UE[2]\n",
    "  qtdCycle = 100/cycle\n",
    "  onTimes = np.array([offL])\n",
    "  i = 1\n",
    "  while i <= qtdCycle:\n",
    "    onTimes = np.append(onTimes, (cycle * i) + onTimes[0])\n",
    "    i += 1\n",
    "  return onTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rl4aQdP_GCoP"
   },
   "outputs": [],
   "source": [
    "def inTimes_(UE):\n",
    "  # Retorna o começo de cada in\n",
    "  # Exemplo: 7s------17s-------27s\n",
    "  # Cada tempo representa o fim de um ON, e o começo de um IN antes do próximo offset\n",
    "\n",
    "  onL = UE[3]\n",
    "  cycle = UE[2]\n",
    "  offL = UE[4]\n",
    "  qtdCycle = 100/cycle\n",
    "  in_ = np.array([(offL + onL + 1)])\n",
    "  i = 1\n",
    "  while i <= qtdCycle:\n",
    "    in_ = np.append(in_, (cycle * i) + in_[0])\n",
    "    i += 1\n",
    "\n",
    "  return in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0mqDTd8psdq"
   },
   "outputs": [],
   "source": [
    "def timeOff(UE, tcs):\n",
    "  # Retorna a latência devida ao offset para cada UE\n",
    "\n",
    "  offs = offsets_(UE).astype(int)\n",
    "  ons = onTimes_(UE).astype(int)\n",
    "  taO = np.zeros(len(tcs))\n",
    "  aux = []\n",
    "  if offs[0] != ons[0]:\n",
    "    i = 0\n",
    "    for tc2 in tcs:\n",
    "      for off, on in zip(offs, ons):\n",
    "        if (off <= tc2 <= on):\n",
    "          aux.append(on - tc2)\n",
    "        else:\n",
    "          aux.append(0)\n",
    "\n",
    "      taO[i] = sum(aux)\n",
    "      i += 1\n",
    "      aux.clear()\n",
    "\n",
    "  return taO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kq8Dg3FTsirq"
   },
   "outputs": [],
   "source": [
    "def timeIn(tcs, UE):\n",
    "  # Retorna a latência devida à cada tempo IN de cada UE\n",
    "\n",
    "  cycle = UE[2]\n",
    "  onL = UE[3]\n",
    "  offL = UE[4]\n",
    "  offs = offsets_(UE).astype(int)\n",
    "  ins = inTimes_(UE).astype(int)\n",
    "  aux = []\n",
    "  taI = np.zeros(len(tcs))\n",
    "  if cycle != onL:\n",
    "    i = 0\n",
    "    for tc2 in tcs:\n",
    "      for inn, off in zip(ins, offs):\n",
    "        if (inn <= tc2 <= (off + cycle + 1)):\n",
    "            aux.append(offL + (off + cycle + 1 - tc2))\n",
    "        else:\n",
    "          aux.append(0)\n",
    "\n",
    "      taI[i] = sum(aux)\n",
    "      i += 1\n",
    "      aux.clear()\n",
    "\n",
    "  return taI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IL-JrnctqD4D"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "def arrivalTimePoisson():\n",
    "  tcs = np.linspace(0, 100, 1000)\n",
    "  return tcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8p4BxxTZmUrk"
   },
   "outputs": [],
   "source": [
    "def latencyCycle(tc, dfUE):\n",
    "  # Retorna a latência devido aos tempos de inatividade em cada ciclo, o sleep\n",
    "  lc = []\n",
    "  for UE in dfUE.itertuples():\n",
    "    taI = timeIn(tc, UE)\n",
    "    taO = timeOff(UE, tc)\n",
    "    latencyCycle = taI + taO\n",
    "    lc.append(latencyCycle.tolist())\n",
    "  dfUE['Latency_Cycle'] = lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRQndSaNYoNa"
   },
   "outputs": [],
   "source": [
    "# Mapeia a quantidade máxima de UEs por DCI para cada BWP\n",
    "def calculate_kmax(bwp, user_type):\n",
    "    kmax_map = {\n",
    "        'URLLC': {25000: 5, 30000: 6, 40000: 8, 50000: 10},\n",
    "        'eMBB': {\n",
    "            25000: 5, 30000: 6, 20000: 4, 5000: 1,\n",
    "            10000: 2, 15000: 3, 40000: 8, 50000: 10\n",
    "        }\n",
    "    }\n",
    "    return kmax_map[user_type].get(bwp, 1)\n",
    "\n",
    "# Calcula os tempos de DCI para cada UE\n",
    "def assign_dci_times(kmax_arr, on_time_arr, cycle_length_arr, columns):\n",
    "    aux = np.zeros((len(kmax_arr), columns), dtype=int)\n",
    "\n",
    "    for column in range(columns):\n",
    "        aux_list = []\n",
    "\n",
    "        for i, kmax in enumerate(kmax_arr):\n",
    "            if i not in aux_list:\n",
    "                indexes = np.where(kmax_arr == kmax)[0].tolist()\n",
    "                aux_list.extend(indexes)\n",
    "\n",
    "                k, group = 0, 0\n",
    "                #qtd_group = on_time_arr[i] // kmax\n",
    "                if kmax == 0:\n",
    "                    qtd_group = 0\n",
    "                else:\n",
    "                    qtd_group = len(indexes) // kmax\n",
    "\n",
    "                for ue in indexes:\n",
    "                    if k % kmax == 0 and k != 0:\n",
    "                        group += 1\n",
    "                    if group >= qtd_group and group % qtd_group == 0:\n",
    "                        k = 0\n",
    "\n",
    "                    if group < qtd_group:\n",
    "                        aux[ue][column] = group\n",
    "                    elif group < qtd_group * 2:\n",
    "                        aux[ue][column] = group + cycle_length_arr[ue]\n",
    "                    else:\n",
    "                        aux[ue][column] = group + 2 * cycle_length_arr[ue]\n",
    "\n",
    "                    k += 1\n",
    "\n",
    "    return aux\n",
    "\n",
    "# Calcula a latência devido ao DCI para cada UE\n",
    "def DCI(df):\n",
    "    # Separar os dataframes por tipo de usuário\n",
    "    df1 = df.query(\"Usuário == 'URLLC'\")\n",
    "    df2 = df.query(\"Usuário == 'eMBB'\")\n",
    "\n",
    "    # Preparar arrays de kmax, onTime, e Cycle Length\n",
    "    kmax1 = np.array([calculate_kmax(bwp, 'URLLC') for bwp in df1['BWP [MHz]']])\n",
    "    kmax2 = np.array([calculate_kmax(bwp, 'eMBB') for bwp in df2['BWP [MHz]']])\n",
    "\n",
    "    # Atribuir tempos de DCI\n",
    "    aux1 = assign_dci_times(kmax1, np.array(df1['onTime [ms]']), np.array(df1['Cycle Length [ms]']), len(df1['Latency_Cycle'].iloc[0]))\n",
    "    aux2 = assign_dci_times(kmax2, np.array(df2['onTime [ms]']), np.array(df2['Cycle Length [ms]']), len(df2['Latency_Cycle'].iloc[0]))\n",
    "\n",
    "    # Adicionar colunas de tempo de DCI\n",
    "    df1['DCI_time'] = aux1.tolist()\n",
    "    df2['DCI_time'] = aux2.tolist()\n",
    "\n",
    "    # Concatenar e retornar o dataframe original com a coluna DCI_time\n",
    "    df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    df['DCI_time'] = df_combined['DCI_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8KhWh9v-P0l"
   },
   "outputs": [],
   "source": [
    "# Calcula a latência devido ao tempo gasto na transmissão de cada pacote\n",
    "def transmissionTime(df, tcs):\n",
    "  sizes = np.array(df['Packet Size [bytes]'])\n",
    "  capacities = np.array(df['Shannon_Capacity'])\n",
    "  tT = []\n",
    "\n",
    "  for size, capacity in zip(sizes, capacities):\n",
    "    aux = []\n",
    "    for i in range(np.size(tcs)):\n",
    "      aux.append(size/capacity)  \n",
    "    tT.append(aux)\n",
    "\n",
    "  df['Transmission_time'] = tT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPfHkqGxkR4j"
   },
   "outputs": [],
   "source": [
    "# Calcula a latência total de cada UE\n",
    "def totalLatency1(df):\n",
    "  latencyCycle = np.array(df['Latency_Cycle'])\n",
    "  tT = np.array(df['Transmission_time'])\n",
    "  dci = np.array(df['DCI_time'])\n",
    "\n",
    "  totalLatencyaux = latencyCycle + dci\n",
    "  totalLatency = totalLatencyaux + tT\n",
    "  df['Total_Latency'] = totalLatency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbQC_vx7D1Li"
   },
   "outputs": [],
   "source": [
    "def power(df):\n",
    "    for row in df.itertuples(index=True):\n",
    "        # Atualizar a coluna 'Power' para cada linha\n",
    "        df.at[row.Index, 'Power'] = sum(df.at[row.Index, 'Transmission_time'])\n",
    "    \n",
    "    # Transformar a coluna 'Power' em uma lista\n",
    "    Pit = df['Power'].tolist()\n",
    "    return Pit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mip import Model, xsum, MINIMIZE, BINARY\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Inicializar os DataFrames de usuários\n",
    "dfUEs = [inicializaUE(2, 8), inicializaUE(3, 7), inicializaUE(4, 6), inicializaUE(5, 5), inicializaUE(6, 4), inicializaUE(7, 3)]\n",
    "tc = arrivalTimePoisson()\n",
    "for df in dfUEs:\n",
    "    transmissionTime(df, tc)\n",
    "\n",
    "# Definir valores possíveis para as variáveis\n",
    "valores_x = [2, 3, 4, 5, 6, 7, 8, 10, 14, 16, 20, 30, 32, 35, 40, 64, 80, 128, 160, 256, 320, 512, 640]\n",
    "valores_y = [1, 2, 3, 4, 5, 6, 8, 10, 20, 30, 40, 50, 60, 80, 100, 200, 300, 400, 500, 600, 800, 1000, 1200, 1600]\n",
    "valores_z = [10, 20, 32, 40, 60, 64, 70, 80, 128, 160, 256, 320, 512, 640, 1024, 1280, 2048, 2560, 5120, 10240, 20480]\n",
    "valores_w = [1, 2, 3, 4, 5, 6, 8, 10, 20, 30, 40, 50, 60, 80, 100, 200, 300, 400, 500, 600, 800]\n",
    "valores_h = [0, 10, 20, 32, 40, 60, 64, 70, 80, 128, 160, 256, 320, 512, 640, 1024, 1280, 2048, 2560, 5120, 10240]\n",
    "\n",
    "# Função para calcular a latência total para usuários URLLC\n",
    "def totalLatency(df, x, y):\n",
    "    latencias = xsum((x[i] - y[i]) for i in range(len(x)))  # Alteração aqui para x - y\n",
    "    return latencias\n",
    "\n",
    "# Função para otimizar URLLC e eMBB com prioridade para capacidade de Shannon\n",
    "def optimize_for_all_users(df):\n",
    "    # Criar o modelo com objetivo de minimizar\n",
    "    model = Model(sense=MINIMIZE)\n",
    "\n",
    "    # Obter os índices dos usuários URLLC e eMBB\n",
    "    urllc_indices = df.query(\"Usuário == 'URLLC'\").index\n",
    "    embb_indices = df.query(\"Usuário == 'eMBB'\").index\n",
    "\n",
    "    # Criar variáveis binárias para escolher exatamente um valor de x e y para cada usuário URLLC\n",
    "    bin_x = [[model.add_var(var_type=BINARY) for _ in range(len(valores_x))] for _ in urllc_indices]\n",
    "    bin_y = [[model.add_var(var_type=BINARY) for _ in range(len(valores_y))] for _ in urllc_indices]\n",
    "\n",
    "    # Criar variáveis binárias para escolher exatamente um valor de z, w e h para cada usuário eMBB\n",
    "    bin_z = [[model.add_var(var_type=BINARY) for _ in range(len(valores_z))] for _ in embb_indices]\n",
    "    bin_w = [[model.add_var(var_type=BINARY) for _ in range(len(valores_w))] for _ in embb_indices]\n",
    "    bin_h = [[model.add_var(var_type=BINARY) for _ in range(len(valores_h))] for _ in embb_indices]\n",
    "\n",
    "    # Garantir que apenas um valor seja selecionado para cada variável de cada usuário\n",
    "    for i in range(len(bin_x)):\n",
    "        model += xsum(bin_x[i]) == 1  # Apenas um valor de x por usuário URLLC\n",
    "        model += xsum(bin_y[i]) == 1  # Apenas um valor de y por usuário URLLC\n",
    "    for i in range(len(bin_z)):\n",
    "        model += xsum(bin_z[i]) == 1  # Apenas um valor de z por usuário eMBB\n",
    "        model += xsum(bin_w[i]) == 1  # Apenas um valor de w por usuário eMBB\n",
    "        model += xsum(bin_h[i]) == 1  # Apenas um valor de h por usuário eMBB\n",
    "\n",
    "    # Definir as variáveis x, y, z, w e h como os valores selecionados diretamente dos vetores\n",
    "    x = [xsum(bin_x[i][j] * valores_x[j] for j in range(len(bin_x[i]))) for i in range(len(bin_x))]\n",
    "    y = [xsum(bin_y[i][j] * valores_y[j] for j in range(len(bin_y[i]))) for i in range(len(bin_y))]\n",
    "    z = [xsum(bin_z[i][j] * valores_z[j] for j in range(len(bin_z[i]))) for i in range(len(bin_z))]\n",
    "    w = [xsum(bin_w[i][j] * valores_w[j] for j in range(len(bin_w[i]))) for i in range(len(bin_w))]\n",
    "    h = [xsum(bin_h[i][j] * valores_h[j] for j in range(len(bin_h[i]))) for i in range(len(bin_h))]\n",
    "\n",
    "    # Adicionar restrições\n",
    "    for i in range(len(urllc_indices)):\n",
    "        model += y[i] + 0.5 * y[i] <= x[i]  # Restrição y + 0.5 * y <= x\n",
    "\n",
    "    for i in range(len(embb_indices)):\n",
    "        model += w[i] + h[i] <= z[i]  # Restrição w + h <= z\n",
    "\n",
    "    # Penalizar os usuários URLLC e eMBB de forma diferente para induzir variações\n",
    "    total_power = xsum(1000 * x[i] + 70 * y[i] for i in range(len(x))) + \\\n",
    "                  xsum(1000 * z[i] + 30 * w[i] + 20 * h[i] for i in range(len(z)))\n",
    "\n",
    "    # Definir a função objetivo no modelo\n",
    "    model.objective = total_power\n",
    "\n",
    "    # Criar variáveis binárias auxiliares para garantir variações\n",
    "    bin_x_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(x))]\n",
    "    bin_y_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(y))]\n",
    "    bin_z_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(z))]\n",
    "    bin_w_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(w))]\n",
    "\n",
    "    # Restrições de variação relaxada para 50% dos usuários\n",
    "    M = 1000  # Constante suficientemente grande para a restrição\n",
    "    for i in range(1, len(x)):\n",
    "        model += x[i] - x[i-1] >= -M * bin_x_diff[i-1]\n",
    "        model += y[i] - y[i-1] >= -M * bin_y_diff[i-1]\n",
    "\n",
    "    for i in range(1, len(z)):\n",
    "        model += z[i] - z[i-1] >= -M * bin_z_diff[i-1]\n",
    "        model += w[i] - w[i-1] >= -M * bin_w_diff[i-1]\n",
    "\n",
    "    # Exigir que pelo menos 50% dos usuários apresentem variação\n",
    "    model += xsum(bin_x_diff) >= len(urllc_indices) * 0.5\n",
    "    model += xsum(bin_y_diff) >= len(urllc_indices) * 0.5\n",
    "    model += xsum(bin_z_diff) >= len(embb_indices) * 0.5\n",
    "    model += xsum(bin_w_diff) >= len(embb_indices) * 0.5\n",
    "\n",
    "    # Restrições de latência para URLLC: a latência total deve ser menor que 15 ms\n",
    "    model += totalLatency(df.query(\"Usuário == 'URLLC'\"), x, y) <= 5  # Latência menor que 5 ms\n",
    "\n",
    "    # Resolver o modelo\n",
    "    model.optimize()\n",
    "\n",
    "    # Verificar se uma solução foi encontrada\n",
    "    if model.num_solutions:\n",
    "        print(f\"Solução encontrada para o DataFrame.\")\n",
    "        # Atualizar o DataFrame com os resultados individuais\n",
    "        df.loc[urllc_indices, 'Cycle Length [ms]'] = [int(x[i].x) for i in range(len(x))]\n",
    "        df.loc[urllc_indices, 'onTime [ms]'] = [int(y[i].x) for i in range(len(y))]\n",
    "        df.loc[urllc_indices, 'offset [ms]'] = [int(0.5 * y[i].x) for i in range(len(y))]\n",
    "        df.loc[embb_indices, 'Cycle Length [ms]'] = [int(z[i].x) for i in range(len(z))]\n",
    "        df.loc[embb_indices, 'onTime [ms]'] = [int(w[i].x) for i in range(len(w))]\n",
    "        df.loc[embb_indices, 'offset [ms]'] = [int(h[i].x) for i in range(len(h))]\n",
    "    else:\n",
    "        print(f\"Nenhuma solução encontrada para o DataFrame.\")\n",
    "\n",
    "# Otimizar para todos os DataFrames\n",
    "for df in dfUEs:\n",
    "    optimize_for_all_users(df)\n",
    "\n",
    "# Calcular métricas adicionais para cada DataFrame\n",
    "for df in dfUEs:\n",
    "    latencyCycle(tc, df)\n",
    "    DCI(df)\n",
    "    transmissionTime(df, tc)\n",
    "    totalLatency1(df)\n",
    "    power(df)\n",
    "\n",
    "# Concatenar os resultados\n",
    "dfU = pd.concat([df.query(\"Usuário == 'URLLC'\") for df in dfUEs])\n",
    "dfE = pd.concat([df.query(\"Usuário == 'eMBB'\") for df in dfUEs])\n",
    "\n",
    "# Liberar memória\n",
    "del dfUEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlteG2jdHKWz"
   },
   "outputs": [],
   "source": [
    "# Cálculo das variáveis necessarias para a CDF do PC\n",
    "powerU = np.array(dfU['Power'])\n",
    "powerE = np.array(dfE['Power'])\n",
    "\n",
    "sortPU_1 = np.sort(powerU)\n",
    "pPU_1 = 1.0 * np.arange(len(powerU)) / float(len(powerU) - 1)\n",
    "\n",
    "sortPE_1 = np.sort(powerE)\n",
    "pPE_1 = 1.0 * np.arange(len(powerE)) / float(len(powerE) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrBAYNQiizx-"
   },
   "outputs": [],
   "source": [
    "# Cálculo das variáveis necessarias para a CDF da Capacidade de Shannon\n",
    "capacityU = np.array(dfU['Shannon_Capacity'])\n",
    "capacityE = np.array(dfE['Shannon_Capacity'])\n",
    "\n",
    "sortCaU_1 = np.sort(capacityU)\n",
    "pCaU_1 = 1.0 * np.arange(len(capacityU)) / float(len(capacityU) - 1)\n",
    "\n",
    "sortCaE_1 = np.sort(capacityE)\n",
    "pCaE_1 = 1.0 * np.arange(len(capacityE)) / float(len(capacityE) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgIMiX8UkG7e"
   },
   "outputs": [],
   "source": [
    "# Cálculo das variáveis necessarias para a CDF da latência total\n",
    "latencyU_1 = np.array(dfU['Total_Latency'].tolist()).flatten()\n",
    "\n",
    "latencyE_1 = np.array(dfE['Total_Latency'].tolist()).flatten()\n",
    "\n",
    "sortlU_1 = np.sort(latencyU_1)\n",
    "plU_1 = 1.0 * np.arange(len(latencyU_1)) / float(len(latencyU_1) - 1)\n",
    "\n",
    "sortlE_1 = np.sort(latencyE_1)\n",
    "plE_1 = 1.0 * np.arange(len(latencyE_1)) / float(len(latencyE_1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ek3_m3ZUmJpX"
   },
   "outputs": [],
   "source": [
    "# Cálculo das variáveis necessarias para a CDF do DCI\n",
    "dciU_1 = np.array(dfU['DCI_time'].tolist()).flatten()\n",
    "\n",
    "dciE_1 = np.array(dfE['DCI_time'].tolist()).flatten()\n",
    "\n",
    "sortdciU_1 = np.sort(dciU_1)\n",
    "pdciU_1 = 1.0 * np.arange(len(dciU_1)) / float(len(dciU_1) - 1)\n",
    "\n",
    "sortdciE_1 = np.sort(dciE_1)\n",
    "pdciE_1 = 1.0 * np.arange(len(dciE_1)) / float(len(dciE_1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tE6Z93KRmqki"
   },
   "outputs": [],
   "source": [
    "# Cálculo das variáveis necessarias para a CDF do tempo de transmissão\n",
    "transmitU_1 = np.array(dfU['Transmission_time'].tolist()).flatten()\n",
    "\n",
    "transmitE_1 = np.array(dfE['Transmission_time'].tolist()).flatten()\n",
    "\n",
    "sorttransmitU_1 = np.sort(transmitU_1)\n",
    "ptransmitU_1 = 1.0 * np.arange(len(transmitU_1)) / float(len(transmitU_1) - 1)\n",
    "\n",
    "sorttransmitE_1 = np.sort(transmitE_1)\n",
    "ptransmitE_1 = 1.0 * np.arange(len(transmitE_1)) / float(len(transmitE_1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQHdKXWEm2aK"
   },
   "outputs": [],
   "source": [
    "# Cálculo das variáveis necessarias para a CDF da latência de sleep\n",
    "cycleLaU_1 = np.array(dfU['Latency_Cycle'].tolist()).flatten()\n",
    "\n",
    "cycleLaE_1 = np.array(dfE['Latency_Cycle'].tolist()).flatten()\n",
    "\n",
    "sortcycleLaU_1 = np.sort(cycleLaU_1)\n",
    "pcycleLaU_1 = 1.0 * np.arange(len(cycleLaU_1)) / float(len(cycleLaU_1) - 1)\n",
    "\n",
    "sortcycleLaE_1 = np.sort(cycleLaE_1)\n",
    "pcycleLaE_1 = 1.0 * np.arange(len(cycleLaE_1)) / float(len(cycleLaE_1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRTg3wpALODb"
   },
   "outputs": [],
   "source": [
    "dfU.boxplot(column=['Shannon_Capacity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lWhSmBAaxw5"
   },
   "outputs": [],
   "source": [
    "dfU['Latency_Cycle'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XJrT68gGx17"
   },
   "outputs": [],
   "source": [
    "dfU['Cycle Length [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUDASGkKHLmA"
   },
   "outputs": [],
   "source": [
    "dfU['onTime [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJ3DMVGjHdZQ"
   },
   "outputs": [],
   "source": [
    "dfU['offset [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-43JkEnONKl"
   },
   "outputs": [],
   "source": [
    "dfE.boxplot(column=['Shannon_Capacity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfE['Latency_Cycle'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AstArd3IFHJ0"
   },
   "outputs": [],
   "source": [
    "dfE['Cycle Length [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkYngtQ3FPBe"
   },
   "outputs": [],
   "source": [
    "dfE['onTime [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBo8HWAeFW2r"
   },
   "outputs": [],
   "source": [
    "dfE['offset [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVo_qLvbdGBw"
   },
   "outputs": [],
   "source": [
    "del dfU, dfE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYWA1HY-Q6qv"
   },
   "source": [
    "#**Algorithm 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mip import Model, xsum, MINIMIZE, BINARY\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Inicializar os DataFrames de usuários\n",
    "dfUEs = [inicializaUE(1, 9), inicializaUE(3, 7), inicializaUE(5, 5), inicializaUE(7, 3)]\n",
    "tc = arrivalTimePoisson()\n",
    "for df in dfUEs:\n",
    "    df = df.sort_values(by=['Shannon_Capacity'], ascending=[False])\n",
    "    transmissionTime(df, tc)\n",
    "\n",
    "# Definir valores possíveis para as variáveis\n",
    "valores_x = [2, 3, 4, 5, 6, 7, 8, 10, 14, 16, 20, 30, 32, 35, 40, 64, 80, 128, 160, 256, 320, 512, 640]\n",
    "valores_y = [1, 2, 3, 4, 5, 6, 8, 10, 20, 30, 40, 50, 60, 80, 100, 200, 300, 400, 500, 600, 800, 1000, 1200, 1600]\n",
    "valores_z = [10, 20, 32, 40, 60, 64, 70, 80, 128, 160, 256, 320, 512, 640, 1024, 1280, 2048, 2560, 5120, 10240, 20480]\n",
    "valores_w = [1, 2, 3, 4, 5, 6, 8, 10, 20, 30, 40, 50, 60, 80, 100, 200, 300, 400, 500, 600, 800]\n",
    "valores_h = [0, 10, 20, 32, 40, 60, 64, 70, 80, 128, 160, 256, 320, 512, 640, 1024, 1280, 2048, 2560, 5120, 10240]\n",
    "\n",
    "# Função para calcular a latência total para usuários URLLC\n",
    "def totalLatency(df, x, y):\n",
    "    latencias = xsum((x[i] - y[i]) for i in range(len(x)))  # Alteração aqui para x - y\n",
    "    return latencias\n",
    "\n",
    "# Função para otimizar URLLC e eMBB com prioridade para capacidade de Shannon\n",
    "def optimize_for_all_users(df):\n",
    "    # Ordenar os usuários por Capacidade de Shannon e proximidade do estouro de latência\n",
    "    #df['Latencia_Remaining'] = df['Max_Latency'] - df['Current_Latency']\n",
    "    \n",
    "\n",
    "    # Criar o modelo com objetivo de minimizar\n",
    "    model = Model(sense=MINIMIZE)\n",
    "\n",
    "    # Obter os índices dos usuários URLLC e eMBB após ordenação\n",
    "    urllc_indices = df.query(\"Usuário == 'URLLC'\").index\n",
    "    embb_indices = df.query(\"Usuário == 'eMBB'\").index\n",
    "\n",
    "    # Criar variáveis binárias para escolher exatamente um valor de x e y para cada usuário URLLC\n",
    "    bin_x = [[model.add_var(var_type=BINARY) for _ in range(len(valores_x))] for _ in urllc_indices]\n",
    "    bin_y = [[model.add_var(var_type=BINARY) for _ in range(len(valores_y))] for _ in urllc_indices]\n",
    "\n",
    "    # Criar variáveis binárias para escolher exatamente um valor de z, w e h para cada usuário eMBB\n",
    "    bin_z = [[model.add_var(var_type=BINARY) for _ in range(len(valores_z))] for _ in embb_indices]\n",
    "    bin_w = [[model.add_var(var_type=BINARY) for _ in range(len(valores_w))] for _ in embb_indices]\n",
    "    bin_h = [[model.add_var(var_type=BINARY) for _ in range(len(valores_h))] for _ in embb_indices]\n",
    "\n",
    "    # Garantir que apenas um valor seja selecionado para cada variável de cada usuário\n",
    "    for i in range(len(bin_x)):\n",
    "        model += xsum(bin_x[i]) == 1  # Apenas um valor de x por usuário URLLC\n",
    "        model += xsum(bin_y[i]) == 1  # Apenas um valor de y por usuário URLLC\n",
    "    for i in range(len(bin_z)):\n",
    "        model += xsum(bin_z[i]) == 1  # Apenas um valor de z por usuário eMBB\n",
    "        model += xsum(bin_w[i]) == 1  # Apenas um valor de w por usuário eMBB\n",
    "        model += xsum(bin_h[i]) == 1  # Apenas um valor de h por usuário eMBB\n",
    "\n",
    "    # Definir as variáveis x, y, z, w e h como os valores selecionados diretamente dos vetores\n",
    "    x = [xsum(bin_x[i][j] * valores_x[j] for j in range(len(bin_x[i]))) for i in range(len(bin_x))]\n",
    "    y = [xsum(bin_y[i][j] * valores_y[j] for j in range(len(bin_y[i]))) for i in range(len(bin_y))]\n",
    "    z = [xsum(bin_z[i][j] * valores_z[j] for j in range(len(bin_z[i]))) for i in range(len(bin_z))]\n",
    "    w = [xsum(bin_w[i][j] * valores_w[j] for j in range(len(bin_w[i]))) for i in range(len(bin_w))]\n",
    "    h = [xsum(bin_h[i][j] * valores_h[j] for j in range(len(bin_h[i]))) for i in range(len(bin_h))]\n",
    "\n",
    "    # Adicionar restrições\n",
    "    for i in range(len(urllc_indices)):\n",
    "        model += y[i] + 0.5 * y[i] <= x[i]  # Restrição y + 0.5 * y <= x\n",
    "\n",
    "    for i in range(len(embb_indices)):\n",
    "        model += w[i] + h[i] <= z[i]  # Restrição w + h <= z\n",
    "\n",
    "    # Penalizar os usuários URLLC e eMBB de forma diferente para induzir variações\n",
    "    total_power = xsum(1000 * x[i] + 70 * y[i] for i in range(len(x))) + \\\n",
    "                  xsum(1000 * z[i] + 30 * w[i] + 20 * h[i] for i in range(len(z)))\n",
    "\n",
    "    # Definir a função objetivo no modelo\n",
    "    model.objective = total_power\n",
    "\n",
    "    # Criar variáveis binárias auxiliares para garantir variações\n",
    "    bin_x_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(x))]\n",
    "    bin_y_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(y))]\n",
    "    bin_z_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(z))]\n",
    "    bin_w_diff = [model.add_var(var_type=BINARY) for _ in range(1, len(w))]\n",
    "\n",
    "    # Restrições de variação relaxada para 50% dos usuários\n",
    "    M = 1000  # Constante suficientemente grande para a restrição\n",
    "    for i in range(1, len(x)):\n",
    "        model += x[i] - x[i-1] >= -M * bin_x_diff[i-1]\n",
    "        model += y[i] - y[i-1] >= -M * bin_y_diff[i-1]\n",
    "\n",
    "    for i in range(1, len(z)):\n",
    "        model += z[i] - z[i-1] >= -M * bin_z_diff[i-1]\n",
    "        model += w[i] - w[i-1] >= -M * bin_w_diff[i-1]\n",
    "\n",
    "    # Exigir que pelo menos 80% dos usuários apresentem variação\n",
    "    model += xsum(bin_x_diff) >= len(urllc_indices) * 0.5\n",
    "    model += xsum(bin_y_diff) >= len(urllc_indices) * 0.5\n",
    "    model += xsum(bin_z_diff) >= len(embb_indices) * 0.5\n",
    "    model += xsum(bin_w_diff) >= len(embb_indices) * 0.5\n",
    "\n",
    "    # Restrições de latência para URLLC: a latência total deve ser menor que 5 ms\n",
    "    model += totalLatency(df.query(\"Usuário == 'URLLC'\"), x, y) <= 5  # Latência menor que 5 ms\n",
    "\n",
    "    # Resolver o modelo\n",
    "    model.optimize()\n",
    " # Verificar se uma solução foi encontrada\n",
    "    if model.num_solutions:\n",
    "        print(f\"Solução encontrada para o DataFrame.\")\n",
    "        # Atualizar o DataFrame com os resultados individuais\n",
    "        df.loc[urllc_indices, 'Cycle Length [ms]'] = [int(x[i].x) for i in range(len(x))]\n",
    "        df.loc[urllc_indices, 'onTime [ms]'] = [int(y[i].x) for i in range(len(y))]\n",
    "        df.loc[urllc_indices, 'offset [ms]'] = [int(0.5 * y[i].x) for i in range(len(y))]\n",
    "        df.loc[embb_indices, 'Cycle Length [ms]'] = [int(z[i].x) for i in range(len(z))]\n",
    "        df.loc[embb_indices, 'onTime [ms]'] = [int(w[i].x) for i in range(len(w))]\n",
    "        df.loc[embb_indices, 'offset [ms]'] = [int(h[i].x) for i in range(len(h))]\n",
    "    else:\n",
    "        print(f\"Nenhuma solução encontrada para o DataFrame.\")\n",
    "\n",
    "# Otimizar para todos os DataFrames\n",
    "for df in dfUEs:\n",
    "    optimize_for_all_users(df)\n",
    "\n",
    "# Calcular métricas adicionais para cada DataFrame\n",
    "for df in dfUEs:\n",
    "    latencyCycle(tc, df)\n",
    "    DCI(df)\n",
    "    transmissionTime(df, tc)\n",
    "    totalLatency1(df)\n",
    "    power(df)\n",
    "\n",
    "# Concatenar os resultados\n",
    "dfU = pd.concat([df.query(\"Usuário == 'URLLC'\") for df in dfUEs])\n",
    "dfE = pd.concat([df.query(\"Usuário == 'eMBB'\") for df in dfUEs])\n",
    "\n",
    "# Liberar memória\n",
    "del dfUEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXM4W38nIZ7Y"
   },
   "outputs": [],
   "source": [
    "powerU2 = np.array(dfU['Power'])\n",
    "powerE2 = np.array(dfE['Power'])\n",
    "\n",
    "sortPU_2 = np.sort(powerU2)\n",
    "pPU_2 = 1.0 * np.arange(len(powerU2)) / float(len(powerU2) - 1)\n",
    "\n",
    "sortPE_2 = np.sort(powerE2)\n",
    "pPE_2 = 1.0 * np.arange(len(powerE2)) / float(len(powerE2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcBYIAD_dvaR"
   },
   "outputs": [],
   "source": [
    "capacityU = np.array(dfU['Shannon_Capacity'])\n",
    "capacityE = np.array(dfE['Shannon_Capacity'])\n",
    "\n",
    "sortCaU_2 = np.sort(capacityU)\n",
    "pCaU_2 = 1.0 * np.arange(len(capacityU)) / float(len(capacityU) - 1)\n",
    "\n",
    "sortCaE_2 = np.sort(capacityE)\n",
    "pCaE_2 = 1.0 * np.arange(len(capacityE)) / float(len(capacityE) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHr6X_f7dvaR"
   },
   "outputs": [],
   "source": [
    "latencyU_2 = np.array(list(dfU['Total_Latency'])).flatten()\n",
    "latencyE_2 = np.array(list(dfE['Total_Latency'])).flatten()\n",
    "\n",
    "sortlU_2 = np.sort(latencyU_2)\n",
    "plU_2 = 1.0 * np.arange(len(latencyU_2)) / float(len(latencyU_2) - 1)\n",
    "\n",
    "sortlE_2 = np.sort(latencyE_2)\n",
    "plE_2 = 1.0 * np.arange(len(latencyE_2)) / float(len(latencyE_2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dznI6I1dvaR"
   },
   "outputs": [],
   "source": [
    "dciU_2 = np.array(list(dfU['DCI_time'])).flatten()\n",
    "dciE_2 = np.array(list(dfE['DCI_time'])).flatten()\n",
    "\n",
    "sortdciU_2 = np.sort(dciU_2)\n",
    "pdciU_2 = 1.0 * np.arange(len(dciU_2)) / float(len(dciU_2) - 1)\n",
    "\n",
    "sortdciE_2 = np.sort(dciE_2)\n",
    "pdciE_2 = 1.0 * np.arange(len(dciE_2)) / float(len(dciE_2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRwAfGlMdvaR"
   },
   "outputs": [],
   "source": [
    "transmitU_2 = np.array(list(dfU['Transmission_time'])).flatten()\n",
    "transmitE_2 = np.array(list(dfE['Transmission_time'])).flatten()\n",
    "\n",
    "sorttransmitU_2 = np.sort(transmitU_2)\n",
    "ptransmitU_2 = 1.0 * np.arange(len(transmitU_2)) / float(len(transmitU_2) - 1)\n",
    "\n",
    "sorttransmitE_2 = np.sort(transmitE_2)\n",
    "ptransmitE_2 = 1.0 * np.arange(len(transmitE_2)) / float(len(transmitE_2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IBtQ22ldvaS"
   },
   "outputs": [],
   "source": [
    "cycleLaU_2 = np.array(list(dfU['Latency_Cycle'])).flatten()\n",
    "cycleLaE_2 = np.array(list(dfE['Latency_Cycle'])).flatten()\n",
    "\n",
    "sortcycleLaU_2 = np.sort(cycleLaU_2)\n",
    "pcycleLaU_2 = 1.0 * np.arange(len(cycleLaU_2)) / float(len(cycleLaU_2) - 1)\n",
    "\n",
    "sortcycleLaE_2 = np.sort(cycleLaE_2)\n",
    "pcycleLaE_2 = 1.0 * np.arange(len(cycleLaE_2)) / float(len(cycleLaE_2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kk7gvGtUILV9"
   },
   "outputs": [],
   "source": [
    "dfU.boxplot(column=['Shannon_Capacity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfU['Latency_Cycle'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0T8UHwo4ILWZ"
   },
   "outputs": [],
   "source": [
    "dfU['Cycle Length [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yXohGvdILWZ"
   },
   "outputs": [],
   "source": [
    "dfU['onTime [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qj27zKo7ILWZ"
   },
   "outputs": [],
   "source": [
    "dfU['offset [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DboKSSYIILWb"
   },
   "outputs": [],
   "source": [
    "dfE.boxplot(column=['Shannon_Capacity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfE['Latency_Cycle'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6C4c9ATILWc"
   },
   "outputs": [],
   "source": [
    "dfE['Cycle Length [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6oLkHMFILWc"
   },
   "outputs": [],
   "source": [
    "dfE['onTime [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZ1zBCQJILWc"
   },
   "outputs": [],
   "source": [
    "dfE['offset [ms]'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-kGsc-UdvaT"
   },
   "outputs": [],
   "source": [
    "del dfU, dfE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpQHaB0TIMcY"
   },
   "source": [
    "#**CDF`s Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTKoF8yLJYAm"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortCaU_1, pCaU_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortCaU_2, pCaU_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Shannon Capacity URLLC', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWA3otyoKbun"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortlU_1, plU_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortlU_2, plU_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Total Latency URLLC [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2b4lkUxfe_1"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortdciU_1, pdciU_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortdciU_2, pdciU_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('DCI Latency URLLC [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIXEma9afpaK"
   },
   "outputs": [],
   "source": [
    "plt.plot(sorttransmitU_1, ptransmitU_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sorttransmitU_2, ptransmitU_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Transmission Latency URLLC [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqKn8Kjwf45E"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortcycleLaU_1, pcycleLaU_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortcycleLaU_2, pcycleLaU_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Sleep Latency URLLC [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sl9KnIkBf8Aq"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortCaE_1, pCaE_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortCaE_2, pCaE_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Shanon Capacity eMBB [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFZBN2GvgHAy"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortlE_1, plE_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortlE_2, plE_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Total Latency eMBB [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4OsZsmys543"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortdciE_1, pdciE_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortdciE_2, pdciE_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('DCI Latency eMBB [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OgEjVyWtJxG"
   },
   "outputs": [],
   "source": [
    "plt.plot(sorttransmitE_1, ptransmitE_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sorttransmitE_2, ptransmitE_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Transmission Latency eMBB [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvQ6C9M8te_s"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortcycleLaE_1, pcycleLaE_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortcycleLaE_2, pcycleLaE_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Sleep Latency eMBB [ms]', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnzzW-PEIvfH"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortPU_1, pPU_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortPU_2, pPU_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Power consumption [mW] - URLLC', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KytgIpRfJk_8"
   },
   "outputs": [],
   "source": [
    "plt.plot(sortPE_1, pPE_1, \"-g\", label=\"Algorithm 1\")\n",
    "plt.plot(sortPE_2, pPE_2, \"-r\", label=\"Algorithm 2\")\n",
    "plt.legend(loc=\"lower right\", fontsize=20)\n",
    "plt.xlabel('Power consumption [mW] - eMBB', fontsize=20)\n",
    "plt.ylabel('CDF', fontsize=20)\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
